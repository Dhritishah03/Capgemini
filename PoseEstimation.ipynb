{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70841aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov7'...\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/WongKinYiu/yolov7.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95095f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhriti Shah\\Downloads\\yolov7\n"
     ]
    }
   ],
   "source": [
    "%cd yolov7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b854a3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec3e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  153M    0  767k    0     0   482k      0  0:05:26  0:00:01  0:05:25  834k\n",
      "  4  153M    4 7756k    0     0  2994k      0  0:00:52  0:00:02  0:00:50 4039k\n",
      " 11  153M   11 17.5M    0     0  4997k      0  0:00:31  0:00:03  0:00:28 6142k\n",
      " 18  153M   18 28.8M    0     0  6436k      0  0:00:24  0:00:04  0:00:20 7535k\n",
      " 26  153M   26 40.3M    0     0  7391k      0  0:00:21  0:00:05  0:00:16 8397k\n",
      " 34  153M   34 52.7M    0     0  8198k      0  0:00:19  0:00:06  0:00:13 10.4M\n",
      " 42  153M   42 65.4M    0     0  8829k      0  0:00:17  0:00:07  0:00:10 11.5M\n",
      " 51  153M   51 78.9M    0     0  9391k      0  0:00:16  0:00:08  0:00:08 12.2M\n",
      " 58  153M   58 89.3M    0     0  9535k      0  0:00:16  0:00:09  0:00:07 12.0M\n",
      " 66  153M   66  101M    0     0  9818k      0  0:00:16  0:00:10  0:00:06 12.2M\n",
      " 74  153M   74  114M    0     0   9.8M      0  0:00:15  0:00:11  0:00:04 12.3M\n",
      " 82  153M   82  126M    0     0  10.0M      0  0:00:15  0:00:12  0:00:03 12.2M\n",
      " 87  153M   87  133M    0     0   9.8M      0  0:00:15  0:00:13  0:00:02 10.9M\n",
      " 92  153M   92  141M    0     0  9949k      0  0:00:15  0:00:14  0:00:01 10.4M\n",
      " 98  153M   98  150M    0     0  9893k      0  0:00:15  0:00:15 --:--:--  9.8M\n",
      "100  153M  100  153M    0     0  9896k      0  0:00:15  0:00:15 --:--:-- 9331k\n"
     ]
    }
   ],
   "source": [
    "! curl -L https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt -o yolov7-w6-pose.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc29c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m letterbox\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m non_max_suppression_kpt\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m output_to_keypoint, plot_skeleton_kpts\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils.datasets'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6801617c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = torch.load(\"C:/Users/Dhriti Shah/Downloads/yolov7/yolov7-w6-pose.pt\", map_location=device)['model']\n",
    "    # Put in inference mode\n",
    "    model.float().eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        # half() turns predictions into float16 tensors\n",
    "        # which significantly lowers inference time\n",
    "        model.half().to(device)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252050ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(image_path, model):\n",
    "    image = cv2.imread(image_path)  # Load the image\n",
    "    # Resize and pad the image\n",
    "    image = letterbox(image, 960, stride=64, auto=True)[0]\n",
    "    # Apply transforms\n",
    "    image = transforms.ToTensor()(image)\n",
    "    # Turn the image into a batch\n",
    "    image = image.unsqueeze(0)\n",
    "    # Perform pose estimation inference\n",
    "    output, _ = model(image)\n",
    "    return output, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e0df1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(output, image):\n",
    "    output = non_max_suppression_kpt(output, \n",
    "                                     0.25, # Confidence Threshold\n",
    "                                     0.65, # IoU Threshold\n",
    "                                     nc=model.yaml['nc'], # Number of Classes\n",
    "                                     nkpt=model.yaml['nkpt'], # Number of Keypoints\n",
    "                                     kpt_label=True)\n",
    "    with torch.no_grad():\n",
    "        output = output_to_keypoint(output)\n",
    "    nimg = image[0].permute(1, 2, 0) * 255\n",
    "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "    for idx in range(output.shape[0]):\n",
    "        plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(nimg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a8c3f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model()\n\u001b[0;32m      2\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Dhriti Shah/Downloads/archive/var_200/VAR/Fouls\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Iterate through images in the folder\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m():\n\u001b[0;32m      2\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Dhriti Shah/Downloads/yolov7/yolov7-w6-pose.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mdevice)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Put in inference mode\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mC:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mC:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1165\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[1;34m(self, mod_name, name)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[1;32m-> 1165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfind_class(mod_name, name)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "image_folder = 'C:/Users/Dhriti Shah/Downloads/archive/var_200/VAR/Fouls'\n",
    "\n",
    "# Iterate through images in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.png', '.jpeg')):  # Ensure you're processing image files\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        # Run inference on the image\n",
    "        output, image = run_inference(image_path, model)\n",
    "        \n",
    "        # Visualize or save the results as needed\n",
    "        # You can use functions like output_to_keypoint and plot_skeleton_kpts to visualize the results\n",
    "        # Or save the results to a file\n",
    "        \n",
    "        # Example: Visualize keypoints and skeletons\n",
    "        visualize_output(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e038318c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7d3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
